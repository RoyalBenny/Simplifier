{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVej6x7nQi80",
        "outputId": "448b98c0-05ad-4b54-f148-b80a76d733a7"
      },
      "source": [
        "!pip install distance\n",
        "!pip install fuzzywuzzy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting distance\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/1a/883e47df323437aefa0d0a92ccfb38895d9416bd0b56262c2e46a47767b8/Distance-0.1.3.tar.gz (180kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 13.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 30kB 14.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 71kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 81kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 92kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 102kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 122kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 133kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 143kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 153kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 163kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 174kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 5.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: distance\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-cp37-none-any.whl size=16275 sha256=a377eeea598a1d754f8b3357dbdd949a116fbc6272e74781eecc60c9ba33d77d\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/aa/e1/dbba9e7b6d397d645d0f12db1c66dbae9c5442b39b001db18e\n",
            "Successfully built distance\n",
            "Installing collected packages: distance\n",
            "Successfully installed distance-0.1.3\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfzxns_MQ3x7",
        "outputId": "f451530a-223d-4f2f-e8ab-08dae9205d86"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "yF8FC70AQ7I_",
        "outputId": "3408969a-6382-4885-fd93-da18f3193874"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from subprocess import check_output\n",
        "%matplotlib inline\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import distance\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import distance\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "from fuzzywuzzy import fuzz\n",
        "from sklearn.manifold import TSNE\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from os import path\n",
        "from PIL import Image"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "mye5ZXtAREw2",
        "outputId": "20d06a9d-8324-4dd1-c6ed-9bdc66dac49a"
      },
      "source": [
        "df = pd.read_csv(\"new_test.csv\")\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_id</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
              "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Should I have a hair transplant at age 24? How...</td>\n",
              "      <td>How much cost does hair transplant require?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>What but is the best way to send money from Ch...</td>\n",
              "      <td>What you send money to China?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Which food not emulsifiers?</td>\n",
              "      <td>What foods fibre?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>How \"aberystwyth\" start reading?</td>\n",
              "      <td>How their can I start reading?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   test_id  ...                                          question2\n",
              "0        0  ...  Why did Microsoft choose core m3 and not core ...\n",
              "1        1  ...        How much cost does hair transplant require?\n",
              "2        2  ...                      What you send money to China?\n",
              "3        3  ...                                  What foods fibre?\n",
              "4        4  ...                     How their can I start reading?\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcnrFQc6RJVc",
        "outputId": "c328d8fc-e483-4997-bf2e-290f5249129f"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 501 entries, 0 to 500\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   test_id    501 non-null    int64 \n",
            " 1   question1  501 non-null    object\n",
            " 2   question2  501 non-null    object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 11.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTa1WmGxRRBq"
      },
      "source": [
        "nan_data = df[df.isnull().any(1)]\n",
        "df = df.fillna('')\n",
        "nan_data = df[df.isnull().any(1)]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "SOqvMYklRT9V",
        "outputId": "cf6be726-5d0e-40f2-8b9d-2ae450dc01c4"
      },
      "source": [
        "if os.path.isfile('feature_tm_test.csv'):\n",
        "    df = pd.read_csv(\"feature_tm_test.csv\",encoding='latin-1')\n",
        "else:\n",
        "    def normalized_common_word(row):\n",
        "        w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
        "        w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
        "        return 1.0 * len(w1 & w2)\n",
        "\n",
        "    def normalized_total_word(row):\n",
        "        w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
        "        w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
        "        return 1.0 * (len(w1) + len(w2))\n",
        "\n",
        "    def normalized_word_share(row):\n",
        "        w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
        "        w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
        "        return 1.0 * len(w1 & w2)/(len(w1) + len(w2))\n",
        "\n",
        "    def get_2_gram_share(row):\n",
        "        q1_list = str(row['question1']).lower().split()\n",
        "        q2_list = str(row['question2']).lower().split()\n",
        "        q1_2_gram = set([i for i in zip(q1_list, q1_list[1:])])\n",
        "        q2_2_gram = set([i for i in zip(q2_list, q2_list[1:])])\n",
        "        shared_2_gram = q1_2_gram.intersection(q2_2_gram)\n",
        "        if len(q1_2_gram) + len(q2_2_gram) == 0:\n",
        "            R2gram = 0\n",
        "        else:\n",
        "            R2gram = len(shared_2_gram) / (len(q1_2_gram) + len(q2_2_gram))\n",
        "        return R2gram\n",
        "\n",
        "    df['ques1_len'] = df['question1'].str.len() \n",
        "    df['ques2_len'] = df['question2'].str.len()\n",
        "    df['len_diff'] = df['ques1_len'] - df['ques2_len']\n",
        "    \n",
        "    df['q1_word_len'] = df['question1'].apply(lambda row: len(row.split(\" \")))\n",
        "    df['q2_word_len'] = df['question2'].apply(lambda row: len(row.split(\" \")))\n",
        "    df['words_diff'] = df['q1_word_len'] - df['q2_word_len']\n",
        "    \n",
        "    df['q1_caps_count'] = df['question1'].apply(lambda x:sum(1 for i in str(x) if i.isupper()))\n",
        "    df['q2_caps_count'] = df['question2'].apply(lambda x:sum(1 for i in str(x) if i.isupper()))\n",
        "    df['caps_diff'] = df['q1_caps_count'] - df['q2_caps_count']\n",
        "    \n",
        "    df['q1_char_len'] = df['question1'].apply(lambda x: len(str(x).replace(' ', '')))\n",
        "    df['q2_char_len'] = df['question2'].apply(lambda x: len(str(x).replace(' ', '')))\n",
        "    df['diff_char_len'] = df['q1_char_len'] - df['q2_char_len']\n",
        "    \n",
        "    df['avg_word_len1'] = df['q1_char_len'] / df['q1_word_len']\n",
        "    df['avg_word_len2'] = df['q2_char_len'] / df['q2_word_len']\n",
        "    df['diff_avg_word'] = df['avg_word_len1'] - df['avg_word_len2']\n",
        "    df['common_word'] = df.apply(normalized_common_word, axis=1)\n",
        "    df['total_word'] = df.apply(normalized_total_word, axis=1)\n",
        "    df['word_share'] = df.apply(normalized_word_share, axis=1)\n",
        "    df['share_2_gram'] = df.apply(get_2_gram_share, axis=1) \n",
        "\n",
        "\n",
        "\n",
        "    df.to_csv(\"feature_tm_test.csv\", index=False)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_id</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>ques1_len</th>\n",
              "      <th>ques2_len</th>\n",
              "      <th>len_diff</th>\n",
              "      <th>q1_word_len</th>\n",
              "      <th>q2_word_len</th>\n",
              "      <th>words_diff</th>\n",
              "      <th>q1_caps_count</th>\n",
              "      <th>q2_caps_count</th>\n",
              "      <th>caps_diff</th>\n",
              "      <th>q1_char_len</th>\n",
              "      <th>q2_char_len</th>\n",
              "      <th>diff_char_len</th>\n",
              "      <th>avg_word_len1</th>\n",
              "      <th>avg_word_len2</th>\n",
              "      <th>diff_avg_word</th>\n",
              "      <th>common_word</th>\n",
              "      <th>total_word</th>\n",
              "      <th>word_share</th>\n",
              "      <th>share_2_gram</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
              "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
              "      <td>57</td>\n",
              "      <td>68</td>\n",
              "      <td>-11</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>-3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>55</td>\n",
              "      <td>-8</td>\n",
              "      <td>4.272727</td>\n",
              "      <td>3.928571</td>\n",
              "      <td>0.344156</td>\n",
              "      <td>2.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.043478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Should I have a hair transplant at age 24? How...</td>\n",
              "      <td>How much cost does hair transplant require?</td>\n",
              "      <td>66</td>\n",
              "      <td>43</td>\n",
              "      <td>23</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>53</td>\n",
              "      <td>37</td>\n",
              "      <td>16</td>\n",
              "      <td>3.785714</td>\n",
              "      <td>5.285714</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.105263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>What but is the best way to send money from Ch...</td>\n",
              "      <td>What you send money to China?</td>\n",
              "      <td>60</td>\n",
              "      <td>29</td>\n",
              "      <td>31</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>47</td>\n",
              "      <td>24</td>\n",
              "      <td>23</td>\n",
              "      <td>3.357143</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>-0.642857</td>\n",
              "      <td>4.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.055556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Which food not emulsifiers?</td>\n",
              "      <td>What foods fibre?</td>\n",
              "      <td>27</td>\n",
              "      <td>17</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>How \"aberystwyth\" start reading?</td>\n",
              "      <td>How their can I start reading?</td>\n",
              "      <td>32</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>-2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>29</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>7.250000</td>\n",
              "      <td>4.166667</td>\n",
              "      <td>3.083333</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.125000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   test_id  ... share_2_gram\n",
              "0        0  ...     0.043478\n",
              "1        1  ...     0.105263\n",
              "2        2  ...     0.055556\n",
              "3        3  ...     0.000000\n",
              "4        4  ...     0.125000\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39-aQTjQSz1-",
        "outputId": "198d342b-fb55-4f48-e5ad-fdf8635c129e"
      },
      "source": [
        "if os.path.isfile('feature_tm_test.csv'):\n",
        "    df_tm = pd.read_csv(\"feature_tm_test.csv\",encoding='latin-1')\n",
        "    print(df_tm.isna().sum())\n",
        "    df_tm = df_tm.fillna('')\n",
        "    df_tm.head()\n",
        "else:\n",
        "    print(\"There is no feature_tm_test.csv!\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_id          0\n",
            "question1        0\n",
            "question2        0\n",
            "ques1_len        0\n",
            "ques2_len        0\n",
            "len_diff         0\n",
            "q1_word_len      0\n",
            "q2_word_len      0\n",
            "words_diff       0\n",
            "q1_caps_count    0\n",
            "q2_caps_count    0\n",
            "caps_diff        0\n",
            "q1_char_len      0\n",
            "q2_char_len      0\n",
            "diff_char_len    0\n",
            "avg_word_len1    0\n",
            "avg_word_len2    0\n",
            "diff_avg_word    0\n",
            "common_word      0\n",
            "total_word       0\n",
            "word_share       0\n",
            "share_2_gram     0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDWVzP5UTQkw",
        "outputId": "28f81f7a-eaf3-4095-f83e-ae90d4e4796c"
      },
      "source": [
        "print(df.isna().sum())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_id          0\n",
            "question1        0\n",
            "question2        0\n",
            "ques1_len        0\n",
            "ques2_len        0\n",
            "len_diff         0\n",
            "q1_word_len      0\n",
            "q2_word_len      0\n",
            "words_diff       0\n",
            "q1_caps_count    0\n",
            "q2_caps_count    0\n",
            "caps_diff        0\n",
            "q1_char_len      0\n",
            "q2_char_len      0\n",
            "diff_char_len    0\n",
            "avg_word_len1    0\n",
            "avg_word_len2    0\n",
            "diff_avg_word    0\n",
            "common_word      0\n",
            "total_word       0\n",
            "word_share       0\n",
            "share_2_gram     0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RDxkIEvTTCi",
        "outputId": "c1ce90f0-2d1e-488a-8d75-c8aa46ecf625"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "SAFE_DIV = 0.0001 \n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "STOP_WORDS = stopwords.words('english')\n",
        "\n",
        "def preprocess(x):\n",
        "    x = str(x).lower()\n",
        "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
        "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
        "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
        "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
        "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
        "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
        "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
        "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
        "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
        "    \n",
        "    \n",
        "    porter = PorterStemmer()\n",
        "    pattern = re.compile('\\W')\n",
        "    \n",
        "    if type(x) == type(''):\n",
        "        x = re.sub(pattern, ' ', x)\n",
        "    \n",
        "    \n",
        "    if type(x) == type(''):\n",
        "        x = porter.stem(x)\n",
        "        example1 = BeautifulSoup(x)\n",
        "        x = example1.get_text()\n",
        "               \n",
        "    \n",
        "    return x\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuVWo_viTWBE"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import pickle\n",
        "import gensim\n",
        "\n",
        "# Download GloVe model\n",
        "# !wget http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "# !unzip glove.840B.300d.zip\n",
        "\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove2word2vec(glove_input_file=\"glove.840B.300d.txt\", word2vec_output_file=\"glove_vectors.txt\")\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "glove_model = KeyedVectors.load_word2vec_format(\"glove_vectors.txt\", binary=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HWztJsNTc1m"
      },
      "source": [
        "from scipy.stats import skew, kurtosis\n",
        "from scipy.spatial.distance import cosine, cityblock, canberra, euclidean, minkowski\n",
        "\n",
        "def remove_stop(sentence):\n",
        "    sentence  = str(sentence)\n",
        "    if sentence == None:\n",
        "        return ' '\n",
        "    if sentence == np.nan:\n",
        "        return ' '\n",
        "    if sentence == 'NaN':\n",
        "        return ' '\n",
        "    z = [i for i in sentence.split() if i not in STOP_WORDS]\n",
        "    return ' '.join(z)\n",
        "\n",
        "def wmd(s1, s2, model):\n",
        "    s1 = str(s1)\n",
        "    s2 = str(s2)\n",
        "    s1 = s1.split()\n",
        "    s2 = s2.split()\n",
        "    return model.wmdistance(s1, s2)\n",
        "\n",
        "def g2w2v(list_of_sent, model, d):\n",
        "    sent_vectors = []\n",
        "    for sentence in list_of_sent: \n",
        "        doc = [word for word in sentence if word in model.wv.vocab] \n",
        "        if doc:\n",
        "            sent_vec = np.mean(model.wv[doc],axis=0) \n",
        "        else:\n",
        "            sent_vec = np.zeros(d)\n",
        "        sent_vectors.append(sent_vec)\n",
        "    return sent_vectors\n",
        "\n",
        "def get_distance_features(df):\n",
        "    \n",
        "    print(\"Extracting Distance Features..\")\n",
        "    \n",
        "    df['question1'] = df.question1.apply(remove_stop)\n",
        "    df['question2'] = df.question2.apply(remove_stop)\n",
        "    df['word_mover_dist'] = df.apply(lambda x: wmd(x['question1'], x['question2'],glove_model), axis=1)\n",
        "    \n",
        "    print(\"- wmd done...\")\n",
        "    \n",
        "    \n",
        "    list_of_question1=[]\n",
        "    for sentence in df.question1.values:\n",
        "        list_of_question1.append(sentence.split())\n",
        "    \n",
        "    list_of_question2=[]\n",
        "    for sentence in df.question2.values:\n",
        "        list_of_question2.append(sentence.split())\n",
        "    \n",
        "    g2w2v_q1 = g2w2v(list_of_question1, glove_model, 300)\n",
        "    g2w2v_q2 = g2w2v(list_of_question2, glove_model, 300)\n",
        "    \n",
        "    print(\"- embedding done...\")\n",
        "    \n",
        "    df['cosine_dist'] = [cosine(q1, q2) for (q1, q2) in zip(g2w2v_q1,g2w2v_q2)]\n",
        "    df['cityblock_dist'] = [cityblock(q1, q2) for (q1, q2) in zip(g2w2v_q1,g2w2v_q2)]\n",
        "    df['canberra_dist'] = [canberra(q1, q2) for (q1, q2) in zip(g2w2v_q1,g2w2v_q2)]\n",
        "    df['euclidean_dist'] = [euclidean(q1, q2) for (q1, q2) in zip(g2w2v_q1,g2w2v_q2)]\n",
        "    df['minkowski_dist'] = [minkowski(q1, q2) for (q1, q2) in zip(g2w2v_q1,g2w2v_q2)]\n",
        "    \n",
        "    print('- spatial distance done')\n",
        "    \n",
        "    df.cosine_dist = df.cosine_dist.fillna(0)\n",
        "    df.word_mover_dist = df.word_mover_dist.apply(lambda wmd: 30 if wmd == np.inf else wmd )\n",
        "   \n",
        "    return df"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJQPRUQqUU2j"
      },
      "source": [
        "def get_token_features(q1, q2):\n",
        "    token_features = [0.0]*10\n",
        "    \n",
        "    q1_tokens = q1.split()\n",
        "    q2_tokens = q2.split()\n",
        "\n",
        "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
        "        return token_features\n",
        "    \n",
        "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
        "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
        "    \n",
        "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
        "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
        "    \n",
        "    common_word_count = len(q1_words.intersection(q2_words))\n",
        "    \n",
        "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
        "    \n",
        "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
        "    \n",
        "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
        "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
        "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
        "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
        "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
        "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
        "    \n",
        "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
        "    \n",
        "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
        "    \n",
        "    token_features[8] = abs(len(q1_tokens) - len(q2_tokens))\n",
        "    \n",
        "    token_features[9] = (len(q1_tokens) + len(q2_tokens))/2\n",
        "    return token_features\n",
        "\n",
        "\n",
        "def get_longest_substr_ratio(a, b):\n",
        "    strs = list(distance.lcsubstrings(a, b))\n",
        "    if len(strs) == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return len(strs[0]) / (min(len(a), len(b)) + 1)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okXvI7FWUWvB"
      },
      "source": [
        "def extract_features(df):\n",
        "    df[\"question1\"] = df[\"question1\"].fillna(\"\").apply(preprocess)\n",
        "    df[\"question2\"] = df[\"question2\"].fillna(\"\").apply(preprocess)\n",
        "\n",
        "    print(\"Extracting Token Features...\")\n",
        "    \n",
        "    token_features = df.apply(lambda x: get_token_features(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    \n",
        "    df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
        "    df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
        "    df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
        "    df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
        "    df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
        "    df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
        "    df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
        "    df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))\n",
        "    df[\"abs_len_diff\"]  = list(map(lambda x: x[8], token_features))\n",
        "    df[\"mean_len\"]      = list(map(lambda x: x[9], token_features))\n",
        "   \n",
        "    print(\"Extracting Fuzzy Features..\")\n",
        "\n",
        "    df[\"token_set_ratio\"]       = df.apply(lambda x: fuzz.token_set_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    df[\"token_sort_ratio\"]      = df.apply(lambda x: fuzz.token_sort_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    df[\"fuzz_ratio\"]            = df.apply(lambda x: fuzz.QRatio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    df[\"fuzz_partial_ratio\"]    = df.apply(lambda x: fuzz.partial_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    df[\"longest_substr_ratio\"]  = df.apply(lambda x: get_longest_substr_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    return df"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "gnpt8_-mUYyE",
        "outputId": "3ce3e5e8-b311-4836-8b87-1e37139d96f4"
      },
      "source": [
        "if os.path.isfile('feature_nlp_test.csv'):\n",
        "    df_nlp = pd.read_csv(\"feature_nlp_test.csv\",encoding='latin-1')\n",
        "    # df.fillna('')\n",
        "else:\n",
        "    print(\"Extracting features for test:\")\n",
        "    df = pd.read_csv(\"new_test.csv\")\n",
        "    df = extract_features(df)\n",
        "    df = get_distance_features(df)\n",
        "    df = df.drop(['question1','question2'], axis=1)\n",
        "    df.to_csv(\"feature_nlp_test.csv\", index=False)\n",
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting features for test:\n",
            "Extracting Token Features...\n",
            "Extracting Fuzzy Features..\n",
            "Extracting Distance Features..\n",
            "- wmd done...\n",
            "- embedding done...\n",
            "- spatial distance done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_id</th>\n",
              "      <th>cwc_min</th>\n",
              "      <th>cwc_max</th>\n",
              "      <th>csc_min</th>\n",
              "      <th>csc_max</th>\n",
              "      <th>ctc_min</th>\n",
              "      <th>ctc_max</th>\n",
              "      <th>last_word_eq</th>\n",
              "      <th>first_word_eq</th>\n",
              "      <th>abs_len_diff</th>\n",
              "      <th>mean_len</th>\n",
              "      <th>token_set_ratio</th>\n",
              "      <th>token_sort_ratio</th>\n",
              "      <th>fuzz_ratio</th>\n",
              "      <th>fuzz_partial_ratio</th>\n",
              "      <th>longest_substr_ratio</th>\n",
              "      <th>word_mover_dist</th>\n",
              "      <th>cosine_dist</th>\n",
              "      <th>cityblock_dist</th>\n",
              "      <th>canberra_dist</th>\n",
              "      <th>euclidean_dist</th>\n",
              "      <th>minkowski_dist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.599988</td>\n",
              "      <td>0.333330</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.272725</td>\n",
              "      <td>0.214284</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>12.5</td>\n",
              "      <td>54</td>\n",
              "      <td>50</td>\n",
              "      <td>37</td>\n",
              "      <td>45</td>\n",
              "      <td>0.241379</td>\n",
              "      <td>5.377619</td>\n",
              "      <td>0.212743</td>\n",
              "      <td>32.914707</td>\n",
              "      <td>158.719900</td>\n",
              "      <td>2.450075</td>\n",
              "      <td>2.450075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.799984</td>\n",
              "      <td>0.571420</td>\n",
              "      <td>0.499975</td>\n",
              "      <td>0.142855</td>\n",
              "      <td>0.714276</td>\n",
              "      <td>0.357140</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>10.5</td>\n",
              "      <td>82</td>\n",
              "      <td>58</td>\n",
              "      <td>47</td>\n",
              "      <td>56</td>\n",
              "      <td>0.386364</td>\n",
              "      <td>2.885574</td>\n",
              "      <td>0.082187</td>\n",
              "      <td>22.012440</td>\n",
              "      <td>127.354115</td>\n",
              "      <td>1.689144</td>\n",
              "      <td>1.689144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.999967</td>\n",
              "      <td>0.499992</td>\n",
              "      <td>0.666644</td>\n",
              "      <td>0.333328</td>\n",
              "      <td>0.833319</td>\n",
              "      <td>0.357140</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>10.0</td>\n",
              "      <td>92</td>\n",
              "      <td>55</td>\n",
              "      <td>57</td>\n",
              "      <td>83</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>3.004117</td>\n",
              "      <td>0.094164</td>\n",
              "      <td>26.997807</td>\n",
              "      <td>123.466020</td>\n",
              "      <td>1.951432</td>\n",
              "      <td>1.951432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>53</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>7.164147</td>\n",
              "      <td>0.391609</td>\n",
              "      <td>73.987938</td>\n",
              "      <td>177.060048</td>\n",
              "      <td>5.201015</td>\n",
              "      <td>5.201015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.999950</td>\n",
              "      <td>0.666644</td>\n",
              "      <td>0.999900</td>\n",
              "      <td>0.249994</td>\n",
              "      <td>0.749981</td>\n",
              "      <td>0.499992</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>74</td>\n",
              "      <td>66</td>\n",
              "      <td>70</td>\n",
              "      <td>73</td>\n",
              "      <td>0.483871</td>\n",
              "      <td>3.298204</td>\n",
              "      <td>0.247688</td>\n",
              "      <td>40.107086</td>\n",
              "      <td>147.543857</td>\n",
              "      <td>3.130887</td>\n",
              "      <td>3.130887</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   test_id   cwc_min   cwc_max  ...  canberra_dist  euclidean_dist  minkowski_dist\n",
              "0        0  0.599988  0.333330  ...     158.719900        2.450075        2.450075\n",
              "1        1  0.799984  0.571420  ...     127.354115        1.689144        1.689144\n",
              "2        2  0.999967  0.499992  ...     123.466020        1.951432        1.951432\n",
              "3        3  0.000000  0.000000  ...     177.060048        5.201015        5.201015\n",
              "4        4  0.999950  0.666644  ...     147.543857        3.130887        3.130887\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xIRS0y_Ut7Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}